---
title: Bayesian analysis of longitudinal multilevel data using brms and rethinking - part 4  
summary: Some more musings and explorations that didn't fit into the main posts of this series.
author: Andreas Handel
date: '2022-02-25'
lastMod: "2022-04-20"
slug: longitudinal-multilevel-bayesian-analysis-4
categories: 
- R
- Data Analysis
tags: 
- R
- Data Analysis
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
---



<p>This is a continuation with some side analyses of <a href="/posts/longitudinal-multilevel-bayesian-analysis-1/">this tutorial</a> illustrating how one can use the <code>brms</code> and <code>rethinking</code> R packages to perform a Bayesian analysis of longitudinal data using a multilevel/hierarchical/mixed-effects setup.</p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>I assume you read through the main posts of the tutorial, namely <a href="/posts/longitudinal-multilevel-bayesian-analysis-1/">this one describing model setup and data generation</a>, and <a href="/posts/longitudinal-multilevel-bayesian-analysis-2/">this one describing fitting with rethinking</a>. You probably also looked at the <a href="/posts/longitudinal-multilevel-bayesian-analysis-3/">fitting with <code>brms</code></a> post, though that‚Äôs optional.</p>
<p>Here, I‚Äôm doing a few additional explorations that just didn‚Äôt fit into the other posts.</p>
</div>
<div id="who-this-is-not-for" class="section level1">
<h1>Who this is (not) for</h1>
<p>This is only for you if you read my main tutorial posts and enjoyed my musings and explorations enough that you want to see some more stuff üòÅ.</p>
</div>
<div id="r-setup" class="section level1">
<h1>R setup</h1>
<p>Again as previously, the code shown below are housed in 2 separate R scripts, which you can get <a href="/posts/longitudinal-multilevel-bayesian-analysis-4/part4fitmodels.R">here</a> and <a href="/posts/longitudinal-multilevel-bayesian-analysis-4/part4exploremodels.R">here</a>. You can run the scripts one after the other. The code chunks don‚Äôt quite show up in that order in this post.</p>
<p>We need the same packages as previously. See comments in previous posts on how to get <code>Stan</code> installed and working.</p>
<pre class="r"><code>library(&#39;fs&#39;) #for file path
library(&#39;ggplot2&#39;) # for plotting
library(&#39;cmdstanr&#39;) #for model fitting
library(&#39;rethinking&#39;) #for model fitting</code></pre>
<p>These are additional packages for the exploration part.</p>
<pre class="r"><code>library(&#39;dplyr&#39;) # for data manipulation
library(&#39;ggplot2&#39;) # for plotting
library(&#39;cmdstanr&#39;) #for model fitting
library(&#39;rethinking&#39;) #for model fitting
library(&#39;fs&#39;) #for file path</code></pre>
</div>
<div id="defining-a-few-functions" class="section level1">
<h1>Defining a few functions</h1>
<p>For the explorations below, I will repeat some parts (fitting and plotting).
For simplicity and to streamline code, I defined a few functions that I‚Äôm using repeatedly.</p>
<p>This function specifies the fitting part:</p>
<pre class="r"><code>######################################
# Function to fit each model
######################################
# function to run fit so I don&#39;t need to keep repeating
# some parameters are set globally.
# not very clean code but good enough for here :)
fitfunction &lt;- function(model, data, start, constraints)
{
  tstart=proc.time(); #capture current time

  fl$fit &lt;- ulam(flist = model,
                 data = data,
                 start=start,
                 constraints=constraints,
                 log_lik=TRUE, cmdstan=TRUE,
                 control=list(adapt_delta=adapt_delta, max_treedepth = max_td),
                 chains=chains, cores = cores,
                 warmup = warmup, iter = iter
  )# end ulam statement

  tend=proc.time(); #capture current time
  tdiff=tend-tstart;
  runtime_minutes=tdiff[[3]]/60;

  #add some more things to the fit object
  fl$runtime = runtime_minutes
  fl$model = names(model)

  return(fl)
}</code></pre>
<p>This function does the prediction for the different models:</p>
<pre class="r"><code># defining a function so I don&#39;t need to re-type the same code
predfunction &lt;- function(fl,fitdat)
{

  #this will contain all the predictions from the different models
  fitpred = vector(mode = &quot;list&quot;, length = length(fl))

  # we are looping over each fitted model
  for (n in 1:length(fl))
  {
    #get current model
    nowmodel = fl[[n]]$fit

    #make new data for which we want predictions
    #specifically, more time points so the curves are smoother
    timevec = seq(from = 0.1, to = max(fitdat$time), length=100)
    Ntot = max(fitdat$id)
    #new data used for predictions
    #make variables for all versions of dose we use
    preddat = data.frame( id = sort(rep(seq(1,Ntot),length(timevec))),
                          time = rep(timevec,Ntot),
                          dose = 0,
                          dose_adj = 0,
                          dose_adj2 = 0,
                          dose_cat = &quot;0&quot;,
                          dose_cat2 = 0
    )
    #add right dose information for each individual
    for (k in 1:Ntot)
    {
      #get actual dose for a given individual
      #assign that dose
      #need the if statements because not every data set has each dose
      if (&quot;dose&quot; %in% names(fitdat)) {
        nowdose = unique(fitdat$dose[fitdat$id == k])
        preddat[(preddat$id == k),&quot;dose&quot;] = nowdose
      }
      if (&quot;dose_adj&quot; %in% names(fitdat)) {
        nowdose_adj = unique(fitdat$dose_adj[fitdat$id == k])
        preddat[(preddat$id == k),&quot;dose_adj&quot;] = nowdose_adj
      }
      if (&quot;dose_adj2&quot; %in% names(fitdat)) {
        nowdose_adj2 = unique(fitdat$dose_adj2[fitdat$id == k])
        preddat[(preddat$id == k),&quot;dose_adj2&quot;] = nowdose_adj2
      }
      if (&quot;dose_cat&quot; %in% names(fitdat)) {
        nowdose_cat = unique(fitdat$dose_cat[fitdat$id == k])
        preddat[(preddat$id == k),&quot;dose_cat&quot;] = as.character(nowdose_cat)
      }
      if (&quot;dose_cat2&quot; %in% names(fitdat)) {
        nowdose_cat2 = unique(fitdat$dose_cat2[fitdat$id == k])
        preddat[(preddat$id == k),&quot;dose_cat2&quot;] = nowdose_cat2
      }
    }

    # pull out posterior samples for the parameters
    post &lt;- extract.samples(nowmodel)

    # estimate and CI for parameter variation
    # this uses the link function from rethinking
    # we ask for predictions for the new data generated above
    linkmod &lt;- rethinking::link(nowmodel, data = preddat)

    #computing mean and various credibility intervals
    #these choices are inspired by the Statistical Rethinking book
    #and purposefully do not include 95%
    #to minimize thoughts of statistical significance
    #significance is not applicable here since we are doing bayesian fitting
    modmean &lt;- apply( linkmod$mu , 2 , mean )
    modPI79 &lt;- apply( linkmod$mu , 2 , PI , prob=0.79 )
    modPI89 &lt;- apply( linkmod$mu , 2 , PI , prob=0.89 )
    modPI97 &lt;- apply( linkmod$mu , 2 , PI , prob=0.97 )

    # estimate and CI for prediction intervals
    # this uses the sim function from rethinking
    # the predictions factor in additional uncertainty around the mean (mu)
    # as indicated by sigma
    simmod &lt;- rethinking::sim(nowmodel, data = preddat)

    # mean and credible intervals for outcome predictions
    # modmeansim should agree with above modmean values
    modmeansim &lt;- apply( simmod , 2 , mean )
    modPIsim &lt;- apply( simmod , 2 , PI , prob=0.89 )

    #place all predictions into a data frame
    #and store in a list for each model
    fitpred[[n]] = data.frame(id = as.factor(preddat$id),
                              dose = preddat$dose_cat,
                              predtime = preddat$time,
                              Estimate = modmean,
                              Q79lo = modPI79[1,], Q79hi = modPI79[2,],
                              Q89lo = modPI89[1,], Q89hi = modPI89[2,],
                              Q97lo = modPI97[1,], Q97hi = modPI97[2,],
                              Qsimlo=modPIsim[1,], Qsimhi=modPIsim[2,]
    )
  } #end loop over all models
  return(fitpred)
} #end function computing predictions</code></pre>
<p>This function does the plotting:</p>
<pre class="r"><code># defining a function so I don&#39;t need to re-type the same code
plotfunction &lt;- function(fl,fitpred,fitdat)
{
  #list for storing all plots
  plotlist = vector(mode = &quot;list&quot;, length = length(fl))

  #small data adjustment for plotting
  plotdat &lt;- fitdat %&gt;% data.frame()  %&gt;%
    mutate(id = as.factor(id))  %&gt;%
    mutate(dose = dose_cat)


  #looping over all models, creating and storing a plot for each
  for (n in 1:length(fl))
  {
    #adding titles to plots
    title = fl[[n]]$model

    plotlist[[n]] &lt;- ggplot(data = fitpred[[n]], aes(x = predtime, y = Estimate, group = id, color = dose )) +
      geom_line(show.legend = F ) +
      geom_ribbon(aes(x=predtime, ymin=Q89lo, ymax=Q89hi, fill = dose, color = NULL), alpha=0.3, show.legend = F) +
      geom_ribbon(aes(x=predtime, ymin=Qsimlo, ymax=Qsimhi, fill = dose, color = NULL), alpha=0.1, show.legend = F) +
      geom_point(data = plotdat, aes(x = time, y = outcome, group = id, color = dose), shape = 1, size = 2, stroke = 2) +
      scale_y_continuous(limits = c(-30,50)) +
      labs(y = &quot;Virus load&quot;,
           x = &quot;days post infection&quot;) +
      theme_minimal() +
      ggtitle(title)
  }
  return(plotlist)
} #end function making plots</code></pre>
<p>These are the settings we use for all fits shown in this post:</p>
<pre class="r"><code>######################################
# Define general fit settings
######################################
#general settings for fitting
#you might want to adjust based on your computer
warmup = 4000
iter = warmup + floor(warmup/2)
max_td = 17 #tree depth
adapt_delta = 0.999
chains = 5
cores  = chains
seed = 1234</code></pre>
<p>With these function definitions and specifications out of the way, we can get to some more model explorations.</p>
</div>
<div id="alternative-model-for-time-series-trajectory" class="section level1">
<h1>Alternative model for time-series trajectory</h1>
<p>In the main tutorial, I used the following two-parameter model to describe hypothetical virus-load time series for an acute virus infection.</p>
<p><span class="math display">\[
\mu_{i,t} = \log\left( t_i^{\alpha_i} e^{-\beta_i t_i} \right)  
\]</span></p>
<p>I mentioned there that this equation does in fact not capture real data too well. For our research project, we used a somewhat more flexible equation, given as</p>
<p><span class="math display">\[
\mu_{i,t} = \log\left( \frac{2 p_i}{e^{-g_i  (k_i - t_i)} + e^{d_i  (t_i - k_i)}}\right).
\]</span></p>
<p>Instead of two parameters, this model has 4. The parameters approximately represent virus peak, <span class="math inline">\(p_i\)</span>, initial growth rate, <span class="math inline">\(g_i\)</span>, decay rate, <span class="math inline">\(d_i\)</span>, and time of peak, <span class="math inline">\(k_i\)</span>. Colleagues <a href="https://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-11-S1-S10">showed previously</a> that this can fit virus load data for acute infections fairly well. The original use was for influenza, we found that it also worked reasonably well for our norovirus data, and thus used it. For the tutorial, I decided to stick to the simpler 2-parameter model. But everything I discussed there applies to this alternative model. For all 4 parameters, we can define individual-level and population level parameters, make them dose-dependent, etc. The main models for the 4 parameters are:</p>
<p><span class="math display">\[
\begin{aligned}
p_{i} &amp; =  p_{0,i} + p_1 x_i  \\
g_{i} &amp; =  g_{0,i} + g_1 x_i \\
d_{i} &amp; =  d_{0,i} + d_1 x_i \\
k_{i} &amp; =  k_{0,i} + k_1 x_i \\
\end{aligned}
\]</span></p>
<p>In this notation, <span class="math inline">\(x_i\)</span> is the dose, transformed and scaled as needed.</p>
<p>The same ideas about model specification, exponentiating to avoid negative values, and all of that still applies. You now need to specify priors for the parameters in each of the four equations above, instead of the 2 equations we had previously. It‚Äôs conceptionally the same, just a bit more typing and coding.
Since there isn‚Äôt anything fundamentally new to show or learn, I‚Äôm not implementing the code. I‚Äôm confident once you walked through the prior posts in the tutorial, you can copy &amp; paste your way to working code for this bigger model. So if you feel like it, go ahead and implement the above model, both to simulate data and then to fit it.</p>
<p>The model you use to simulate data does not have to be the same you use to fit it. You could for instance try to simulate data with the 2-parameter model and fit with the 4-parameter one, or the reverse. I haven‚Äôt tried it, but I expect that using the 2-parameter model to simulate data and the 4-parameter model to fit should work ok (since the 4 parameter model is flexible enough) but the reverse is likely not working too well. In either case, the fits are likely worse than if you use the same model to simulate the data and fit it. That‚Äôs not surprising.</p>
<p>It illustrates the point that choosing the right main function (likelihood and deterministic part), is at least as important - probably more so - than setting priors. Most non-Bayesians get hung up about priors, but the dirty (somewhat)-secret is that the overall model specification - which needs to be done for both frequentist and Bayesian fitting - often has a much more pronounced impact, and choosing the model structure is always based on expertise (or convention, though that‚Äôs a bad reason), and there are no real rules.</p>
</div>
<div id="fitting-an-alternative-data-set" class="section level1">
<h1>Fitting an alternative data set</h1>
<p>For the main tutorial, I used one of the simulated data sets (as generated by model 3) for fitting purposes, since it had the most realistic structure. But we can of course try to fit the other data sets as well. Here, I‚Äôm doing a quick exploration using data set 2. That was the one generated by model 2, which did not have any individual-level variability. Recall that model 2 did not run well at all, while model 2a (basically the same model, just better specified) worked ok, though the fit was not great. Let‚Äôs see how model 2a does when fitting to a data that has the right overall structure. We‚Äôll compare it to model 4.</p>
<p>Here are the 2 models we want to fit:</p>
<pre class="r"><code>#full-pooling model, population-level parameters only
m2a &lt;- alist(
  outcome ~ dnorm(mu, sigma),
  mu &lt;- exp(alpha)*log(time) - exp(beta)*time,
  alpha &lt;-  a0 + a1*dose_adj,
  beta &lt;-  b0 + b1*dose_adj,
  a0 ~ dnorm(2,  0.1),
  b0 ~ dnorm(0.5, 0.1),
  a1 ~ dnorm(0.3, 1),
  b1 ~ dnorm(-0.3, 1),
  sigma ~ cauchy(0,1)
)</code></pre>
<pre class="r"><code>#adaptive priors, partial-pooling model
m4 &lt;- alist(
  outcome ~ dnorm(mu, sigma),
  mu &lt;- exp(alpha)*log(time) - exp(beta)*time,
  alpha &lt;-  a0[id] + a1*dose_adj,
  beta &lt;-  b0[id] + b1*dose_adj,
  a0[id] ~ dnorm(mu_a,  sigma_a),
  b0[id] ~ dnorm(mu_b, sigma_b),
  mu_a ~ dnorm(2, 1),
  mu_b ~ dnorm(0.5, 1),
  sigma_a ~ cauchy(0, 1),
  sigma_b ~ cauchy(0, 1),
  a1 ~ dnorm(0.3, 1),
  b1 ~ dnorm(-0.3, 1),
  sigma ~ cauchy(0, 1)
)</code></pre>
<p>Setup for fitting these models:</p>
<pre class="r"><code>######################################
# Model fit to alternative data set
######################################
#stick all models into a list
modellist = list(m2a=m2a, m4=m4)
# set up a list in which we&#39;ll store our results
fl = vector(mode = &quot;list&quot;, length = length(modellist))

#now fitting dataset 2 we produced in the first post
#also removing anything in the dataframe that&#39;s not used for fitting
#makes the ulam/Stan code more robust
simdat &lt;- readRDS(&quot;simdat.Rds&quot;)
fitdat = list(id=simdat[[2]]$id,
            outcome = simdat[[2]]$outcome,
            dose_adj = simdat[[2]]$dose_adj,
            dose_cat = simdat[[3]]$dose_cat,
            time = simdat[[2]]$time)
#pulling out number of observations
Ntot = length(unique(fitdat$id))

## Setting starting values
#starting values for model 2
startm2a = list(a0 = 2, b0 = 0.5, a1 = 0.5 , b1 = -0.5, sigma = 1)
#starting values for models 4
startm4 = list(mu_a = 2, sigma_a = 1, mu_b = 0, sigma_b = 1, a1 = 0.5 , b1 = -0.5, sigma = 1)
#put different starting values in list
#need to be in same order as models below
startlist = list(startm2a,startm4)

# defining constraints on parameters
constm2a = list(sigma=&quot;lower=0&quot;)
constm4 = list(sigma=&quot;lower=0&quot;)
constraintlist = list(constm2a,constm4)</code></pre>
<p>Running the fits:</p>
<pre class="r"><code>fl &lt;- NULL
for (n in 1:length(modellist))
{
  cat(&#39;************** \n&#39;)
  cat(&#39;starting model&#39;, names(modellist[n]), &#39;\n&#39;)
  fl[[n]] &lt;- fitfunction(model = modellist[[n]],
                             data = fitdat,
                             start = startlist[[n]],
                             constraints = constraintlist[[n]])
  cat(&#39;model fit took this many minutes:&#39;, fl[[n]]$runtime, &#39;\n&#39;)
  cat(&#39;************** \n&#39;)
}

# saving the results so we can use them later
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_dat2&quot;, ext=&quot;Rds&quot;)
saveRDS(fl,filepath)</code></pre>
<p>Let‚Äôs see what we get for the fits to this changed data set.</p>
<pre class="r"><code>#loading previously saved fits.
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_dat2&quot;, ext=&quot;Rds&quot;)
fl &lt;- readRDS(filepath)
fitdat &lt;- fl[[1]]$fit@data</code></pre>
<pre class="r"><code>#Model 2a
print(precis(fl[[1]]$fit,depth=1),digits = 2)</code></pre>
<pre><code>##        mean     sd   5.5%  94.5% n_eff Rhat4
## a0     3.00 0.0030  2.994  3.003  4272     1
## b0     1.00 0.0027  0.995  1.004  4540     1
## a1     0.10 0.0014  0.098  0.102  5268     1
## b1    -0.10 0.0012 -0.102 -0.098  5907     1
## sigma  0.99 0.0441  0.924  1.065  5020     1</code></pre>
<pre class="r"><code>#Model 4
a0mean = mean(precis(fl[[2]]$fit,depth=2,&quot;a0&quot;)$mean)
b0mean = mean(precis(fl[[2]]$fit,depth=2,&quot;b0&quot;)$mean)
print(precis(fl[[2]]$fit,depth=1),digits = 2)</code></pre>
<pre><code>## 48 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##            mean     sd     5.5%   94.5% n_eff Rhat4
## mu_a     2.9997 0.0030  2.99472  3.0044   378     1
## mu_b     1.0003 0.0027  0.99605  1.0045   395     1
## sigma_a  0.0016 0.0013  0.00019  0.0040   205     1
## sigma_b  0.0021 0.0014  0.00033  0.0048   228     1
## a1       0.0999 0.0014  0.09757  0.1022  1669     1
## b1      -0.1001 0.0013 -0.10217 -0.0981  3191     1
## sigma    0.9861 0.0434  0.91872  1.0562  3874     1</code></pre>
<pre class="r"><code>print(c(a0mean,b0mean))</code></pre>
<pre><code>## [1] 2.999663 1.000287</code></pre>
<p>The estimates for the parameters are fairly similar.</p>
<p>We can compare models:</p>
<pre class="r"><code>comp &lt;- compare(fl[[1]]$fit,fl[[2]]$fit)
print(comp)</code></pre>
<pre><code>##                 WAIC       SE    dWAIC      dSE     pWAIC    weight
## fl[[1]]$fit 749.7644 22.95419 0.000000       NA  4.934354 0.7842277
## fl[[2]]$fit 752.3453 23.11326 2.580951 2.081672 10.448133 0.2157723</code></pre>
<p>Now, with a data structure that does not contain individual level variation, model 2a which does not contain it works ok.</p>
<p>Let‚Äôs look at plots to further see if/how the models differ. First we need to make predictions, then we can plot.</p>
<pre class="r"><code>fitpred &lt;- predfunction(fl,fitdat)</code></pre>
<pre class="r"><code>plotlist &lt;- plotfunction(fl,fitpred,fitdat)
plot(plotlist[[1]])</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_dat2-1.png" width="672" /></p>
<pre class="r"><code>plot(plotlist[[2]])</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_dat2-2.png" width="672" /></p>
<p>For this data set, with little individual-level variation, the simpler model and the more complex one perform more or less equally well.
Depending on the amount of noise (<span class="math inline">\(\sigma\)</span> in the model), at some point we can expect the simple model to not capture things too well anymore.</p>
<p>Generally speaking, model choice should be driven by the underlying scientific assumptions. If one expects no or almost no variation between the individual units (e.g.¬†people in our case, but it could be anything else), then a simple model that ignores individual-level variation might be ok. In most cases, a model that allows for such variation is likely more appropriate. Especially since the adaptive pooling model allows the model to learn the amount of variation that best describes the data, thus it seems - apart from a bit more complex model setup and a longer run time - there is essentially no downside to this type of model.</p>
</div>
<div id="fitting-a-larger-data-set" class="section level1">
<h1>Fitting a larger data set</h1>
<p>The number of individuals in our simulated data in the main tutorial is low. That was motivated by the real data we had. But since the data are simulated, we can explore how things might or might not change if we increase the data. I was especially interested to see how the estimates for <span class="math inline">\(a_1\)</span> and <span class="math inline">\(b_1\)</span> might change with larger samples.</p>
<p>To get larger samples, I ran the simulation script shown in <a href="/posts/longitudinal-multilevel-bayesian-analysis-1/">part 1</a> with a 10 times larger sample size for each group. Everything else stayed the same. Here is the code that fits model 4 to the larger data set.</p>
<p>Setting up things.</p>
<pre class="r"><code>######################################
# Model fit to bigger data set
######################################
#stick all models into a list
modellist = list(m4=m4)
# set up a list in which we&#39;ll store our results
fits = vector(mode = &quot;list&quot;, length = length(modellist))

#fitting dataset with larger sample size
simdat &lt;- readRDS(&quot;simdat_big.Rds&quot;)
fitdat=list(id=simdat[[3]]$id,
            outcome = simdat[[3]]$outcome,
            dose_adj = simdat[[3]]$dose_adj,
            dose_cat = simdat[[3]]$dose_cat,
            time = simdat[[3]]$time
            )

#starting values for model 4
startm4 = list(mu_a = 2, sigma_a = 1, mu_b = 0, sigma_b = 1, a1 = 0.5 , b1 = -0.5, sigma = 1)
startlist = list(startm4)

# defining constraints on parameters
constm4 = list(sigma=&quot;lower=0&quot;,sigma_a=&quot;lower=0&quot;,sigma_b=&quot;lower=0&quot;)
constraintlist = list(constm4)</code></pre>
<p>Running the fits.</p>
<pre class="r"><code># fitting model
fl &lt;- NULL
cat(&#39;************** \n&#39;)
cat(&#39;starting model&#39;, names(modellist[1]), &#39;\n&#39;)
fl[[1]] &lt;- fitfunction(model = modellist[[1]],
                         data = fitdat,
                         start = startlist[[1]],
                         constraints = constraintlist[[1]])
cat(&#39;model fit took this many minutes:&#39;, fl[[1]]$runtime, &#39;\n&#39;)
cat(&#39;************** \n&#39;)

# saving the results so we can use them later
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_big&quot;, ext=&quot;Rds&quot;)
saveRDS(fl,filepath)</code></pre>
<pre class="r"><code>#loading previously saved fits.
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_big&quot;, ext=&quot;Rds&quot;)
fl &lt;- readRDS(filepath)
fitdat &lt;- fl[[1]]$fit@data</code></pre>
<p>Exploring model fits</p>
<pre class="r"><code>a0mean = mean(precis(fl[[1]]$fit,depth=2,&quot;a0&quot;)$mean)
b0mean = mean(precis(fl[[1]]$fit,depth=2,&quot;b0&quot;)$mean)
print(precis(fl[[1]]$fit,depth=1),digits = 2)</code></pre>
<pre><code>## 480 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##           mean     sd   5.5%  94.5% n_eff Rhat4
## mu_a     3.004 0.0067  2.993  3.015 16110     1
## mu_b     0.999 0.0063  0.989  1.009 19929     1
## sigma_a  0.103 0.0049  0.095  0.111 19606     1
## sigma_b  0.097 0.0046  0.090  0.104 18742     1
## a1       0.098 0.0037  0.092  0.104   538     1
## b1      -0.100 0.0033 -0.105 -0.094   545     1
## sigma    1.015 0.0152  0.991  1.040 12241     1</code></pre>
<pre class="r"><code>print(c(a0mean,b0mean))</code></pre>
<pre><code>## [1] 3.003990 0.999272</code></pre>
<p>Note the message about the hidden parameters, it‚Äôs 10 times as many as previously, since we have <span class="math inline">\(N\)</span> increased by a factor of 10. If we compare these estimates to those for model 4 in <a href="/posts/longitudinal-multilevel-bayesian-analysis-2/">part 2</a>, we notice that the credible intervals shrank, i.e.¬†the precision increased. This is expected for larger sample size. So, reassuringly, larger sample size behaves as expected, helping the model to make more precise estimates. This should also lead to narrower uncertainty intervals for the predictions. Let‚Äôs check:</p>
<pre class="r"><code>fitpred &lt;- predfunction(fl,fitdat)</code></pre>
<pre class="r"><code>plotlist &lt;- plotfunction(fl,fitpred,fitdat)
#update plot
p1 &lt;- plotlist[[1]] + scale_y_continuous(limits = c(-30,70))
plot(p1)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_big-1.png" width="672" /></p>
<pre class="r"><code>#save plot so we can use it in the blog post
ggsave(file = paste0(&quot;featured.png&quot;), p1, dpi = 300, units = &quot;in&quot;, width = 6, height = 6)</code></pre>
<p>Looks messy, but overall ok.</p>
</div>
<div id="alternative-to-enforcing-positivity-of-parameters" class="section level1">
<h1>Alternative to enforcing positivity of parameters</h1>
<p>In the main tutorial, we enforced positivity for the main parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> through exponentiation. There are other options. An alternative is to ensure they are positive based on the assigned distributions.</p>
<p>As a reminder, our main model describing the mean trajectory of the data is given by</p>
<p><span class="math display">\[
\mu_{i,t}  = \log\left( T_i^{\alpha_{i}} e^{-\beta_{i} * T_i} \right) 
\]</span>
Only positive values for <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(\beta_i\)</span> produce meaningful trajectories. Thus we need to ensure they are positive. In the main tutorial, I did that by exponentiating them, and then rewriting the equation to minimize potential numerical problems.</p>
<p>Another approach is to keep the parameters the way they are, and specify the rest of the model in such a way that they can only be positive.
The equations determining <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(\beta_i\)</span> are for our case the following:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha_{i} &amp;  =  a_{0,i} + a_1 \left(\log (D_i) - \log (D_m)\right)  \\
\beta_{i} &amp;  =  b_{0,i} + b_1 \left(\log (D_i) - \log (D_m)\right)
\end{aligned}
\]</span>
I‚Äôm going to make a small change by dropping the subtraction of the middle dose. As discussed, we did that for ease of interpretation but otherwise it wasn‚Äôt quite needed.
So I‚Äôm considering a model of this form</p>
<p><span class="math display">\[
\begin{aligned}
\alpha_{i} &amp;  =  a_{0,i} + a_1 \log (D_i)   \\
\beta_{i} &amp;  =  b_{0,i} + b_1 \log (D_i) 
\end{aligned}
\]</span>
We can choose priors for <span class="math inline">\(a_{0,i}\)</span> and <span class="math inline">\(b_{0,i}\)</span> that ensure only positive values. However, the priors for <span class="math inline">\(a_1\)</span> and <span class="math inline">\(b_1\)</span> should be allowed to be either positive or negative, since we don‚Äôt know what impact the dose has. We also don‚Äôt know how strong the dose effect is. That means, with the model above, it is tricky to ensure <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(\beta_i\)</span> are positive.</p>
<p>As mentioned in the main tutorial, we could just leave things as they are and hope that the data will push the fitting routine to reasonable values. That might or might not work, so let‚Äôs try to help things along. To do so, we‚Äôll rewrite the equations a bit as follows:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha_{i} &amp;  =  a_{0,i} \left( 1  + (a_2-1)  \frac{\log (D_i)}{\max(\log(D_i))} \right)  \\
\beta_{i} &amp; =  b_{0,i} \left( 1 + (b_2-1)  \frac{\log (D_i) }{\max(\log(D_i))} \right) 
\end{aligned}
\]</span></p>
<p>This maybe strange rewriting does two things. First, we rescaled the dose variable, such that all values are between 0 and 1.
Additionally, we replaced the parameters <span class="math inline">\(a_1\)</span> and <span class="math inline">\(b_1\)</span> with <span class="math inline">\(a_1 = (a_2-1) a_{0,i}\)</span> and <span class="math inline">\(b_1 = (b_2-1) a_{0,i}\)</span> and reorganized the equation.</p>
<p>This rewriting doesn‚Äôt change the model, but it helps us to now more easily define priors that enforce the equations to be positive. If we give all parameters priors that are positive, it will ensure that the part related to the dose only goes as low as -1 (if <span class="math inline">\(a_2\)</span> or <span class="math inline">\(b_2\)</span> are zero), which means the full equations can only go down to 0 and not lower.
These priors should work:</p>
<p><span class="math display">\[
\begin{aligned}
a_{0,i}  \sim \mathrm{LogNormal}(0, 1) \\
b_{0,i}  \sim \mathrm{LogNormal}(0, 1) \\
a_{2}  \sim \mathrm{LogNormal}(0, 1) \\
b_{2}  \sim \mathrm{LogNormal}(0, 1) \\
\end{aligned}
\]</span></p>
<p>For simplicity, I fixed the priors. You could of course adjust the model above to assign the distributions for <span class="math inline">\(a_{0,i}\)</span> and <span class="math inline">\(b_{0,i}\)</span> their own parameters and give them priors, like we did previously for model 4.</p>
<p>With these choices, we now ensure that <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(\beta_i\)</span> can not become negative. Let‚Äôs run the model using <code>rethinking</code> to see how it works. I‚Äôm comparing it to the previous model 3, with fixed, somewhat regularizing priors. Note the different forms of dose that are used in the models, corresponding to the equations just discussed. (I know I called another model #5 previously, but didn‚Äôt feel like renaming this one. So this is a new model 5 üòÅ.)</p>
<pre class="r"><code>#regularizing prior, partial-pooling model
#no middle dose subtraction
m3a &lt;- alist(
  outcome ~ dnorm(mu, sigma),
  mu &lt;- exp(alpha)*log(time) - exp(beta)*time,
  alpha &lt;-  a0[id] + a1*dose,
  beta &lt;-  b0[id] + b1*dose,
  a0[id] ~ dnorm(2,  1),
  b0[id] ~ dnorm(0.5, 1),
  a1 ~ dnorm(0.3, 1),
  b1 ~ dnorm(-0.3, 1),
  sigma ~ cauchy(0,1)
)</code></pre>
<pre class="r"><code># different way of enforcing positive parameters
m5 &lt;- alist(
  outcome ~ dnorm(mu, sigma),
  mu &lt;- exp(alpha)*log(time) - exp(beta)*time,
  alpha &lt;-  a0[id]*(1 + (a2-1) * dose_adj2),
  beta &lt;-  b0[id]*(1 + (b2-1) *dose_adj2),
  a0[id] ~ dlnorm(0,  1),
  b0[id] ~ dlnorm(0, 1),
  a2 ~ dlnorm(0, 1),
  b2 ~ dlnorm(0, 1),
  sigma ~ cauchy(0,1)
)</code></pre>
<p>Here is the setup up for fitting this model. Note the new variable <code>dose_adj2</code> which is defined as shown in the equations above:</p>
<pre class="r"><code>#stick all models into a list
modellist = list(m3a=m3a, m5=m5)
# set up a list in which we&#39;ll store our results
fits = vector(mode = &quot;list&quot;, length = length(modellist))

#fitting dataset 3 we produced in the earlier post
#also removing anything in the dataframe that&#39;s not used for fitting
#makes the ulam/Stan code more robust
#note that we need both dose_adj and an alternative that divides by max dose
#for model 5
simdat &lt;- readRDS(&quot;simdat.Rds&quot;)
fitdat=list(id=simdat[[3]]$id,
            outcome = simdat[[3]]$outcome,
            dose = simdat[[3]]$dose,
            dose_adj2 = simdat[[3]]$dose/max(simdat[[3]]$dose),
            dose_cat = simdat[[3]]$dose_cat,
            time = simdat[[3]]$time
            )
#pulling out number of observations
Ntot = length(unique(fitdat$id))

#starting values for model 3a
startm3a = list(a0 = rep(2,Ntot), b0 = rep(0.5,Ntot), a2 = 0.5 , b2 = -0.5, sigma = 1)
#starting values for model 5
startm5 = list(a0u = 0, b0u = 0, a2 = 0.5 , b2 = 0.5, sigma = 1)
#put different starting values in list
#need to be in same order as models below
startlist = list(startm3a, startm5)

# defining constraints on parameters
constm3 = list(sigma=&quot;lower=0&quot;)
constm5 = list(sigma=&quot;lower=0&quot;)
constraintlist = list(constm3,constm5)</code></pre>
<p>Running the fits:</p>
<pre class="r"><code># fitting models
fl &lt;- NULL
for (n in 1:length(modellist))
{
  cat(&#39;************** \n&#39;)
  cat(&#39;starting model&#39;, names(modellist[n]), &#39;\n&#39;)
  fl[[n]] &lt;- fitfunction(model = modellist[[n]],
                         data = fitdat,
                         start = startlist[[n]],
                         constraints = constraintlist[[n]])
  cat(&#39;model fit took this many minutes:&#39;, fl[[n]]$runtime, &#39;\n&#39;)
  cat(&#39;************** \n&#39;)
}
# saving the results so we can use them later
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_altpos&quot;, ext=&quot;Rds&quot;)
saveRDS(fl,filepath)</code></pre>
<p>Let‚Äôs see what we get with this changed model.</p>
<pre class="r"><code>#loading previously saved fits.
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_altpos&quot;, ext=&quot;Rds&quot;)
fl &lt;- readRDS(filepath)
fitdat &lt;- fl[[1]]$fit@data</code></pre>
<p>For model 3, we get the same estimates for the dose parameters. That should be the case, since we are still estimating the impact of changes in (log) dose, as before.
The intercept parameters, <span class="math inline">\(a_{0,i}\)</span> and <span class="math inline">\(b_{0,i}\)</span> are now different from previous model fits and the original data generating model. That is also expected, since we generated the data with the model that subtracted the medium dose, but now fit it without that part.</p>
<pre class="r"><code>#Model 3
a0mean = mean(precis(fl[[1]]$fit,depth=2,&quot;a0&quot;)$mean)
b0mean = mean(precis(fl[[1]]$fit,depth=2,&quot;b0&quot;)$mean)
print(precis(fl[[1]]$fit,depth=1),digits = 2)</code></pre>
<pre><code>## 48 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##       mean    sd   5.5% 94.5% n_eff Rhat4
## a1    0.19 0.041 0.1291  0.26   579     1
## b1    0.07 0.037 0.0089  0.13   602     1
## sigma 1.06 0.050 0.9835  1.14  2447     1</code></pre>
<pre class="r"><code>print(c(a0mean,b0mean))</code></pre>
<pre><code>## [1] 2.0707322 0.6309118</code></pre>
<p>For the new model 5, I‚Äôm doing the math so we can compare the new with the old parameters.</p>
<pre class="r"><code>#Model 5
print(precis(fl[[2]]$fit,depth=1),digits = 2)</code></pre>
<pre><code>## 48 vector or matrix parameters hidden. Use depth=2 to show them.</code></pre>
<pre><code>##       mean    sd 5.5% 94.5% n_eff Rhat4
## a2    3.62 0.849 2.48   5.2   312     1
## b2    0.83 0.229 0.51   1.2   286     1
## sigma 1.06 0.053 0.98   1.1  1309     1</code></pre>
<pre class="r"><code>a0mean = mean(precis(fl[[2]]$fit,depth=2,&quot;a0&quot;)$mean)
b0mean = mean(precis(fl[[2]]$fit,depth=2,&quot;b0&quot;)$mean)
print(c(a0mean,b0mean))</code></pre>
<pre><code>## [1] 1.168793 1.129761</code></pre>
<pre class="r"><code># computing values that correspond to a1 and b1
a1est = (precis(fl[[2]]$fit,pars=&quot;a2&quot;)[1,]-1)*a0mean/max(fitdat$dose)
b1est = (precis(fl[[2]]$fit,pars=&quot;b2&quot;)[1,]-1)*b0mean/max(fitdat$dose)
print(c(a1est,b1est))</code></pre>
<pre><code>## [1]  0.44368013 -0.02844121</code></pre>
<p>We find overall similar estimates, but the new model 5 has fairly wide credible intervals.</p>
<p>We can also compare the two models.</p>
<pre class="r"><code>compare(fl[[1]]$fit,fl[[2]]$fit)</code></pre>
<pre><code>##                 WAIC       SE     dWAIC       dSE    pWAIC    weight
## fl[[1]]$fit 832.0189 23.35205 0.0000000        NA 43.31692 0.5245033
## fl[[2]]$fit 832.2151 23.41504 0.1961835 0.4549643 43.50567 0.4754967</code></pre>
<p>The fit quality is more or less the same. Note that model 3 ran faster than model 5, 14 versus 25 minutes.</p>
<p>Finally, let‚Äôs do the plots to check that they look more or less the same.</p>
<pre class="r"><code>fitpred &lt;- predfunction(fl,fitdat)</code></pre>
<p>Now let‚Äôs make and look at the plots.</p>
<pre class="r"><code>plotlist &lt;- plotfunction(fl,fitpred,fitdat)
plot(plotlist[[1]])</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_altpos-1.png" width="672" /></p>
<pre class="r"><code>plot(plotlist[[2]])</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_altpos-2.png" width="672" /></p>
<p>We do find that the plots for the 2 models are pretty much the same. That‚Äôs good, since those are essentially the same models, just written in different forms. In this case, the original way of writing seems better since it runs faster.</p>
</div>
<div id="treating-dose-as-an-unordered-categorical-variable" class="section level1">
<h1>Treating dose as an <strong>unordered</strong> categorical variable</h1>
<p>In the main tutorial, we treated the predictor of interest as continuous. If you have a continuous predictor of interest, that‚Äôs generally the best approach. Dose is a bit of a borderline case. We know the exact dose that was given, but it‚Äôs not clear that one should assume a linear relation between dose and the model parameters. To explore the possible impact of this assumption, one could try all kinds of functional relationships. But without any good scientific knowledge of how that relation should look, it‚Äôs a bit futile. Another option is to try and fit the model with dose treated categorically. At other times, you have a predictor that is categorical from the start, for instance one group receiving treatment and the other not is clearly categorical.</p>
<p>Here is a version of the model we looked at, now with dose treated categorical. I‚Äôm only showing this for the adaptive partial pooling model (model 4), but it could also be implemented for the other models.</p>
<p>The equations change as follows</p>
<p><span class="math display">\[
\begin{align}
\textrm{Outcome} \\
Y_{i,t}   \sim \mathrm{Normal}\left(\mu_{i,t}, \sigma\right) \\
\\
\textrm{Deterministic time-series trajectory} \\
\mu_{i,t}   =  \exp(\alpha_{i}) \log (t_{i}) -\exp(\beta_{i}) t_{i} \\
\\
\textrm{Deterministic models for main parameters} \\
\alpha_{i}   =  a_{0,i} + a_1[dose_i]   \\
\beta_{i}   =  b_{0,i} + b_1[dose_i]  \\
\\
\textrm{Priors} \\
a_{0,i} \sim \mathrm{Normal}(\mu_a, \sigma_a) \\
b_{0,i}  \sim \mathrm{Normal}(\mu_b, \sigma_a) \\
a_1[dose_i] \sim \mathrm{Normal}(0.3, 1) \\
b_1[dose_i] \sim \mathrm{Normal}(-0.3, 1) \\
\mu_a \sim \mathrm{Normal}(2, 1) \\
\mu_b \sim \mathrm{Normal}(0.5, 1) \\
\sigma_a  \sim \mathrm{HalfCauchy}(0,1)  \\
\sigma_b  \sim \mathrm{HalfCauchy}(0,1)  \\
\sigma  \sim \mathrm{HalfCauchy}(0, 1)  \\
\end{align}
\]</span></p>
<p>The difference is that now the parameters <span class="math inline">\(a_1\)</span> and <span class="math inline">\(b_1\)</span> depend on the dose category (low/medium/high) of individual <span class="math inline">\(i\)</span>, instead of the actual dose value for that individual. The rest of the model didn‚Äôt change. Let‚Äôs run this new model, which I call model 6.</p>
<p>Model 6 with dose treated (unordered) categorical. I call the indices for the categorical dose <code>dose_cat2</code>.</p>
<pre class="r"><code>#model with dose treated as categorical
#naming this model m6
m6 &lt;- alist(
  outcome ~ dnorm(mu, sigma),
  mu &lt;- exp(alpha)*log(time) - exp(beta)*time,
  alpha &lt;-  a0[id] + a1[dose_cat2],
  beta &lt;-  b0[id] + b1[dose_cat2],
  a0[id] ~ dnorm(mu_a,  sigma_a),
  b0[id] ~ dnorm(mu_b, sigma_b),
  mu_a ~ dnorm(2, 1),
  mu_b ~ dnorm(0.5, 1),
  sigma_a ~ cauchy(0, 1),
  sigma_b ~ cauchy(0, 1),
  a1[dose_cat] ~ dnorm(0.3, 1),
  b1[dose_cat] ~ dnorm(-0.3, 1),
  sigma ~ cauchy(0, 1)
)</code></pre>
<p>Set up for fitting, running both this new model and the previous model 4 for comparison:</p>
<pre class="r"><code>#stick all models into a list
modellist = list(m4=m4, m6=m6)
# set up a list in which we&#39;ll store our results

#note that we use dose_cat for plotting
#ulam wants categories coded as integers, so we make dose_cat2
simdat &lt;- readRDS(&quot;simdat.Rds&quot;)
fitdat=list(id=simdat[[3]]$id,
            outcome = simdat[[3]]$outcome,
            dose = simdat[[3]]$dose,
            dose_adj = simdat[[3]]$dose_adj,
            dose_cat = simdat[[3]]$dose_cat,
            dose_cat2 = as.numeric(simdat[[3]]$dose_cat),
            time = simdat[[3]]$time)
#pulling out number of observations
Ntot = length(unique(fitdat$id))

#starting values
startm4 = list(mu_a = 2, sigma_a = 1, mu_b = 0, sigma_b = 1, a1 = 0.5 , b1 = -0.5, sigma = 1)
startm6 = list(mu_a = 2, sigma_a = 1, mu_b = 0, sigma_b = 1, a1 = rep(0.3,3) , b1 = rep(-0.3,3), sigma = 1)
startlist = list(startm4, startm6)

# defining constraints on parameters
constm4 = list(sigma=&quot;lower=0&quot;,sigma_a=&quot;lower=0&quot;,sigma_b=&quot;lower=0&quot;)
constm6 = list(sigma=&quot;lower=0&quot;,sigma_a=&quot;lower=0&quot;,sigma_b=&quot;lower=0&quot;)
constraintlist = list(constm4, constm6)</code></pre>
<p>Running the fitting:</p>
<pre class="r"><code># fitting model
fl &lt;- NULL
for (n in 1:length(modellist))
{
  cat(&#39;************** \n&#39;)
  cat(&#39;starting model&#39;, names(modellist[n]), &#39;\n&#39;)
  fl[[n]] &lt;- fitfunction(model = modellist[[n]],
                         data = fitdat,
                         start = startlist[[n]],
                         constraints = constraintlist[[n]])
  cat(&#39;model fit took this many minutes:&#39;, fl[[n]]$runtime, &#39;\n&#39;)
  cat(&#39;************** \n&#39;)
}

# saving the results so we can use them later
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_cat&quot;, ext=&quot;Rds&quot;)
saveRDS(fl,filepath)</code></pre>
<p>Let‚Äôs see what we get with this changed model. I‚Äôm plotting all the coefficients here, so we can see the dose-related ones.</p>
<pre class="r"><code>#loading previously saved fits.
filepath = fs::path(&quot;D:&quot;,&quot;Dropbox&quot;,&quot;datafiles&quot;,&quot;longitudinalbayes&quot;,&quot;ulamfits_cat&quot;, ext=&quot;Rds&quot;)
fl &lt;- readRDS(filepath)
fitdat &lt;- fl[[1]]$fit@data</code></pre>
<pre class="r"><code>#Model 4
print(precis(fl[[1]]$fit,depth=2),digits = 2)</code></pre>
<pre><code>##           mean    sd   5.5%  94.5% n_eff Rhat4
## a0[1]    3.176 0.028  3.131  3.221  1447     1
## a0[2]    3.138 0.028  3.094  3.182  1475     1
## a0[3]    2.943 0.030  2.895  2.989  1642     1
## a0[4]    2.877 0.030  2.830  2.925  1680     1
## a0[5]    2.920 0.030  2.871  2.967  1692     1
## a0[6]    3.011 0.029  2.964  3.057  1591     1
## a0[7]    2.961 0.029  2.914  3.007  1643     1
## a0[8]    2.984 0.015  2.960  3.007  6934     1
## a0[9]    2.911 0.016  2.885  2.936  6642     1
## a0[10]   2.985 0.015  2.961  3.008  6371     1
## a0[11]   2.939 0.015  2.914  2.964  6679     1
## a0[12]   2.845 0.017  2.818  2.873  6902     1
## a0[13]   2.972 0.015  2.947  2.996  6528     1
## a0[14]   3.089 0.014  3.067  3.111  6883     1
## a0[15]   2.951 0.015  2.926  2.975  7503     1
## a0[16]   3.084 0.026  3.043  3.125  1246     1
## a0[17]   2.865 0.027  2.822  2.908  1339     1
## a0[18]   3.040 0.026  2.999  3.083  1287     1
## a0[19]   3.073 0.026  3.031  3.115  1295     1
## a0[20]   3.047 0.026  3.006  3.089  1281     1
## a0[21]   3.023 0.026  2.981  3.065  1283     1
## a0[22]   2.976 0.027  2.934  3.018  1301     1
## a0[23]   2.967 0.027  2.924  3.009  1329     1
## a0[24]   2.916 0.027  2.873  2.959  1329     1
## b0[1]    0.995 0.033  0.941  1.046  1325     1
## b0[2]    0.898 0.033  0.844  0.951  1355     1
## b0[3]    0.943 0.033  0.889  0.995  1286     1
## b0[4]    0.963 0.033  0.910  1.013  1318     1
## b0[5]    1.180 0.032  1.128  1.232  1278     1
## b0[6]    0.931 0.033  0.877  0.982  1328     1
## b0[7]    1.020 0.033  0.967  1.071  1329     1
## b0[8]    1.015 0.013  0.994  1.036  6900     1
## b0[9]    0.909 0.015  0.886  0.933  6609     1
## b0[10]   0.984 0.014  0.962  1.006  6305     1
## b0[11]   1.151 0.012  1.132  1.169  6712     1
## b0[12]   1.049 0.013  1.028  1.069  6897     1
## b0[13]   1.010 0.014  0.988  1.031  6473     1
## b0[14]   0.951 0.014  0.928  0.974  6826     1
## b0[15]   0.794 0.017  0.767  0.820  7374     1
## b0[16]   1.109 0.035  1.056  1.165  1450     1
## b0[17]   0.846 0.036  0.788  0.903  1544     1
## b0[18]   1.106 0.035  1.051  1.162  1459     1
## b0[19]   1.189 0.034  1.136  1.245  1359     1
## b0[20]   0.848 0.037  0.789  0.906  1604     1
## b0[21]   1.057 0.035  1.002  1.113  1445     1
## b0[22]   0.996 0.036  0.939  1.053  1496     1
## b0[23]   0.878 0.036  0.821  0.937  1619     1
## b0[24]   0.854 0.036  0.796  0.914  1540     1
## mu_a     2.987 0.019  2.956  3.018 10535     1
## mu_b     0.986 0.024  0.948  1.025 10542     1
## sigma_a  0.093 0.015  0.072  0.120  8366     1
## sigma_b  0.119 0.019  0.093  0.153  8557     1
## a1       0.086 0.010  0.070  0.103  1076     1
## b1      -0.105 0.014 -0.128 -0.084  1185     1
## sigma    1.062 0.053  0.982  1.149 10064     1</code></pre>
<pre class="r"><code>#Model 6
print(precis(fl[[2]]$fit,depth=2),digits = 2)</code></pre>
<pre><code>##           mean    sd   5.5% 94.5% n_eff Rhat4
## a0[1]    2.677 0.513  1.877  3.50   619     1
## a0[2]    2.640 0.513  1.843  3.46   619     1
## a0[3]    2.444 0.513  1.644  3.27   617     1
## a0[4]    2.379 0.513  1.577  3.21   619     1
## a0[5]    2.422 0.513  1.625  3.25   619     1
## a0[6]    2.513 0.513  1.714  3.34   619     1
## a0[7]    2.463 0.513  1.661  3.29   619     1
## a0[8]    2.529 0.513  1.724  3.35   622     1
## a0[9]    2.456 0.513  1.655  3.28   623     1
## a0[10]   2.530 0.513  1.730  3.35   621     1
## a0[11]   2.484 0.513  1.684  3.30   622     1
## a0[12]   2.390 0.513  1.589  3.21   623     1
## a0[13]   2.517 0.513  1.719  3.34   622     1
## a0[14]   2.635 0.513  1.833  3.45   622     1
## a0[15]   2.496 0.513  1.693  3.32   622     1
## a0[16]   2.589 0.513  1.792  3.41   620     1
## a0[17]   2.371 0.513  1.576  3.19   621     1
## a0[18]   2.546 0.513  1.747  3.37   620     1
## a0[19]   2.579 0.513  1.786  3.40   620     1
## a0[20]   2.553 0.513  1.752  3.37   620     1
## a0[21]   2.529 0.513  1.732  3.35   620     1
## a0[22]   2.481 0.513  1.681  3.30   621     1
## a0[23]   2.472 0.513  1.675  3.29   620     1
## a0[24]   2.422 0.513  1.625  3.24   621     1
## b0[1]    1.070 0.509  0.247  1.90   706     1
## b0[2]    0.974 0.509  0.150  1.81   706     1
## b0[3]    1.018 0.509  0.193  1.85   706     1
## b0[4]    1.038 0.509  0.216  1.87   706     1
## b0[5]    1.255 0.509  0.435  2.09   706     1
## b0[6]    1.006 0.509  0.183  1.84   706     1
## b0[7]    1.095 0.509  0.273  1.93   707     1
## b0[8]    1.097 0.508  0.269  1.94   714     1
## b0[9]    0.992 0.509  0.164  1.83   714     1
## b0[10]   1.067 0.508  0.234  1.90   714     1
## b0[11]   1.233 0.508  0.405  2.07   714     1
## b0[12]   1.131 0.509  0.302  1.97   714     1
## b0[13]   1.092 0.509  0.268  1.93   714     1
## b0[14]   1.033 0.509  0.207  1.87   714     1
## b0[15]   0.876 0.509  0.045  1.72   714     1
## b0[16]   1.186 0.510  0.362  2.03   706     1
## b0[17]   0.923 0.510  0.098  1.77   708     1
## b0[18]   1.183 0.510  0.360  2.03   706     1
## b0[19]   1.267 0.510  0.439  2.11   707     1
## b0[20]   0.925 0.510  0.096  1.76   707     1
## b0[21]   1.134 0.510  0.309  1.98   707     1
## b0[22]   1.073 0.510  0.247  1.91   707     1
## b0[23]   0.955 0.510  0.128  1.80   706     1
## b0[24]   0.931 0.510  0.107  1.77   708     1
## mu_a     2.505 0.512  1.708  3.33   619     1
## mu_b     1.064 0.508  0.242  1.90   708     1
## sigma_a  0.093 0.016  0.071  0.12  2597     1
## sigma_b  0.122 0.021  0.094  0.16  1910     1
## a1[1]    0.300 0.513 -0.530  1.10   618     1
## a1[2]    0.454 0.513 -0.368  1.25   622     1
## a1[3]    0.693 0.513 -0.128  1.49   620     1
## b1[1]    0.168 0.509 -0.665  0.99   706     1
## b1[2]   -0.083 0.508 -0.924  0.74   714     1
## b1[3]   -0.319 0.510 -1.160  0.51   706     1
## sigma    1.062 0.051  0.983  1.15  2603     1</code></pre>
<p>The <span class="math inline">\(a_1\)</span> and <span class="math inline">\(b_1\)</span> coefficients are the interesting ones. We now have a different estimate for each dose. The values for <span class="math inline">\(a_1\)</span> increase with dose and the values for <span class="math inline">\(b_1\)</span> decrease with dose. This is consistent with the linear/continuous model and the way we generated the data.</p>
<p>We can compare this model to the continuous one in terms of WAIC</p>
<pre class="r"><code>compare(fl[[1]]$fit,fl[[2]]$fit)</code></pre>
<pre><code>##                 WAIC       SE    dWAIC       dSE    pWAIC    weight
## fl[[1]]$fit 831.8724 23.41356 0.000000        NA 42.91541 0.6446495
## fl[[2]]$fit 833.0636 23.46125 1.191204 0.5173108 43.45759 0.3553505</code></pre>
<p>Let‚Äôs compute predictions so we can plot.</p>
<pre class="r"><code>fitpred &lt;- predfunction(fl,fitdat)</code></pre>
<p>Now let‚Äôs make and look at the plots.</p>
<pre class="r"><code>plotlist &lt;- plotfunction(fl,fitpred,fitdat)
plot(plotlist[[1]])</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_cat-1.png" width="672" /></p>
<pre class="r"><code>plot(plotlist[[2]])</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot_cat-2.png" width="672" /></p>
<p>The plot looks reasonable, so treating dose here as categorical seems to lead to similar results as treating it continuous. It‚Äôs a scientific question/decision on how to do it. In general, if there are reasons for either approach, my suggestion is to do it both ways and report the additional results as sensitivity analyses.</p>
<div id="a-model-that-doesnt-work" class="section level2">
<h2>A model that ‚Äúdoesn‚Äôt work‚Äù</h2>
<p>When we originally scribbled down models that we might use to fit our data, we came up with this model.</p>
<p><span class="math display">\[
\begin{align}
\textrm{Outcome} \\
Y_{i,t}  \sim \mathrm{Normal}\left(\mu_{i,t}, \sigma\right) \\
\\
\textrm{Deterministic time-series trajectory} \\
\mu_{i,t} =  \exp(\alpha_{i}) \log (t_{i}) -\exp(\beta_{i}) t_{i} \\
\\
\textrm{Distribution for main parameters} \\
\alpha_{i}  \sim \mathrm{Normal}\left(am_{i}, \sigma_a \right)  \\
\beta_{i}  \sim \mathrm{Normal}\left(bm_{i}, \sigma_b \right) \\
\\
\textrm{Deterministic models for main parameters} \\
am_{i}   =  a_{0,i} + a_1 \left(\log (D_i) - \log (D_m)\right)  \\
bm_{i}  =  b_{0,i} + b_1 \left(\log (D_i) - \log (D_m)\right) \\
\\
\textrm{Distribution for (hyper)parameters} \\
a_{0,i}  \sim \mathrm{Normal}(2, 0.1) \\
a_{1}  \sim \mathrm{Normal}(0.5, 0.1) \\
b_{0,i}  \sim \mathrm{Normal}(0, 0.1) \\
b_{1}  \sim \mathrm{Normal}(-0.5, 0.1) \\
\sigma_a  \sim \mathrm{HalfCauchy}(0,1)  \\
\sigma_b  \sim \mathrm{HalfCauchy}(0,1)  \\
\sigma  \sim \mathrm{HalfCauchy}(0,1)  
\end{align}
\]</span></p>
<p>The model is similar to models 1-3, but with another distribution for parameters <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(\beta_i\)</span>. Fitting this model didn‚Äôt work, the fitting routine kept choking. We concluded that with this model we are overfitting. However, I am also not sure if there is something more fundamentally wrong in the way we wrote down this model. I‚Äôm not sure if a mix of having parameters defined by equations, then as distributions and equations again is a generally wrong way. This is currently beyond my Bayesian understanding. Feedback appreciated üòÑ.</p>
<p>It is straightforward to translate the model to <code>rethinking</code> or <code>brms</code> code, but since it didn‚Äôt fit well, and I‚Äôm not even sure if it‚Äôs a ‚Äúproper‚Äù model, there‚Äôs no point in showing the code. Implement it if you want, and let me know if you have some insights into what exactly might be wrong with the model.</p>
</div>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>This post contained a few more explorations of alternative models and model implementations. I know I didn‚Äôt provide as much explanation and detail as I did for the main tutorials. Hopefully, seeing these additional examples is still somewhat helpful. And you know what comes now: For more/real learning of that stuff, you should really check out <a href="https://xcelab.net/rm/statistical-rethinking/">Statistical Rethinking</a> üòÅ.</p>
</div>
<div id="more-things-to-try" class="section level1">
<h1>More things to try</h1>
<p>This section is mainly for myself, some ideas for further extensions. Here are additional topics I can think of. Feel free to provide feedback if you want me to cover some other aspects (no promises of course, it depends on my time and understanding üòÑ).</p>
<ul>
<li>Treating dose as an ordered categorical variable. I started that, but haven‚Äôt finished yet. Hopefully will show up here soon.</li>
<li>Using a scientific/mechanistic/process model based on differential equations to describe the main time-series trajectory.</li>
<li>Exploring individual level variation in dose-dependence, i.e.¬†<span class="math inline">\(a_{1,i}\)</span>, <span class="math inline">\(b_{1,i}\)</span> parameters.</li>
<li>Implementing some of the models in a fully frequentist framework and comparing.</li>
</ul>
<!-- # Treating dose as an __ordered__ categorical variable -->
<!-- For some predictors (e.g. treatment yes/no) there is no ordering. If we assume dose as categorical, there is a clear ordering (Low < Medium < High). If one assumes that an increase in dose has **a monotone impact on the outcome** then one can treat the predictor as ordered categorical variable.  -->
<!-- For our specific example, this is actually not the best idea. The reason is that we are not sure that dose has a monotone impact on the outcomes. But for the sake of illustrating how this could be done, here is an example. Including ordered predictors involves some trickeries, which you can learn about in chapter 12.4 of Statistical Rethinking (2nd edition). I won't attempt to explain the math behind it, I'll just show the code for `ulam`/rethinking`. -->
<!-- To compare with the two versions we just did, I'm implementing model 4 again. -->
<!-- ```{r} -->
<!-- #model with ordered categories -->
<!-- #naming this model m7 -->
<!-- m7 <- alist( -->
<!--   outcome ~ dnorm(mu, sigma), -->
<!--   mu <- exp(alpha)*log(time) - exp(beta)*time, -->
<!--   alpha <-  a0[id] + a1[dose_cat], -->
<!--   beta <-  b0[id] + b1[dose_cat], -->
<!--   a0[id] ~ dnorm(mu_a,  sigma_a), -->
<!--   b0[id] ~ dnorm(mu_b, sigma_b), -->
<!--   mu_a ~ dnorm(2, 1), -->
<!--   mu_b ~ dnorm(0.5, 1), -->
<!--   sigma_a ~ cauchy(0, 1), -->
<!--   sigma_b ~ cauchy(0, 1), -->
<!--   a1 ~ dnorm(0.3, 1), -->
<!--   b1 ~ dnorm(-0.3, 1), -->
<!--   simplex[7]:  -->
<!--   sigma ~ cauchy(0, 1) -->
<!--   ) -->
<!-- ``` -->
</div>
